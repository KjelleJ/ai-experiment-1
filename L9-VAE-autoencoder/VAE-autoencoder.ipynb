{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalfördelning\n",
    "### Kurvan är lägre och bredare vid större spridning (standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# En normalfördelning med 100,000 värden med medelvärde=0 och spridning=1.0\n",
    "distr1 = np.random.normal(loc=0.0, scale=1.0,size=100000)\n",
    "# En normalfördelning med 100,000 värden med medelvärde=0 och spridning=1.5\n",
    "distr2 = np.random.normal(loc=0.0, scale=1.5, size=100000)\n",
    "data = [distr1, distr2]\n",
    "# Vi plottar normalfördelningarna som histogram med 100 intervall (\"hinkar\")\n",
    "# Ger 100 staplar där höjden av varje stapel är ett mått på hur många värden\n",
    "# av fördelningen som finns i det intervallet.\n",
    "_,_,_ = plt.hist(data, 100, density=True, histtype='stepfilled', alpha=0.6)\n",
    "plt.legend([\"dev=1.5\", \"dev=1.0\"], loc =\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition av VAE autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Modell för VAE encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name=\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Lager för sampling (Sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Sampler(layers.Layer):\n",
    "    def call(self, z_mean, z_log_var):\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        z_size = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch_size, z_size))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Modell för VAE decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### VAE modell för träning med encoder, sampler och decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampler = Sampler()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var = self.encoder(data)\n",
    "            z = self.sampler(z_mean, z_log_var)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
    "                    axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            total_loss = reconstruction_loss/30. + tf.reduce_mean(kl_loss)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Om du inte vill träna VAE (tar en timme) ladda från disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "decoder = load_model(\"mnist_decoder_60ep\")\n",
    "encoder = load_model(\"mnist_encoder_60ep\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "mnist_labels = np.concatenate([y_train, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Träna VAE - hoppa över om du laddade från disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# antal epoker\n",
    "neps=30\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "mnist_labels = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(), run_eagerly=True)\n",
    "vae.fit(mnist_digits, epochs=neps, batch_size=128)\n",
    "dir = \"mnist_encoder_\" + str(neps) + \"ep\"\n",
    "#encoder.save(dir)\n",
    "dir = \"mnist_decoder_\" + str(neps) + \"ep\"\n",
    "#decoder.save(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vilken noggrannhet får vi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 30 ep -> 66%\n",
    "# 60 ep -> 77% BÄST! Används i fortsättningen...\n",
    "# 90 ep -> 75%\n",
    "num = 1000\n",
    "err = 0\n",
    "for ix in range(num):\n",
    "    enc = encoder.predict(mnist_digits[ix][np.newaxis])\n",
    "    res = decoder.predict(enc[0])\n",
    "    vae= (clmodel.predict(res[0][np.newaxis]).argmax())\n",
    "    orig = mnist_labels[ix]\n",
    "    if vae!= orig: err = err + 1\n",
    "    plt.show()\n",
    "print(\"Total:\", num, \" errors\", err, \" accuracy:\", 100*(num-err)/num, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Några arrayer och tensorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(type(mnist_digits))\n",
    "print(mnist_digits.shape)\n",
    "print(mnist_digits[0].shape)\n",
    "print(mnist_digits[0][np.newaxis].shape)\n",
    "# z_mean + z_log_var. 2 värden var.\n",
    "enc = encoder(mnist_digits[0][np.newaxis])\n",
    "print(type(enc), enc)\n",
    "print(enc[0], enc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hur ser siffrorna ut före och efter VAE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "clmodel = load_model(\"mnist_classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for ix in range(20):\n",
    "    enc = encoder(mnist_digits[ix][np.newaxis])\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(enc[0])\n",
    "    print(enc[1])\n",
    "    res = decoder(enc[0])\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(mnist_digits[ix], cmap='gray')\n",
    "    orig = mnist_labels[ix]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(res[0], cmap='gray')\n",
    "    vae =(clmodel.predict(res[0][np.newaxis]).argmax())\n",
    "    print(orig, \"after vae:\", vae)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hur kodas siffrorna i planet? Vi kan få en uppfattning genom att ta z från bara z_mean och strunta i tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "encoder = load_model(\"mnist_encoder_60ep\")\n",
    "num = 10000\n",
    "arr = np.zeros((num, 3))\n",
    "for ix in range(num):\n",
    "    enc = encoder(mnist_digits[ix][np.newaxis])\n",
    "    arr[ix, 0] = mnist_labels[ix]\n",
    "    arr[ix, 1] = (enc[0].numpy())[0][0]\n",
    "    arr[ix, 2] = (enc[0].numpy())[0][1]\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 7))\n",
    "for i in range(10):\n",
    "    x = np.zeros((num, 3)) \n",
    "    y = np.zeros((num, 3))\n",
    "    nd = 0\n",
    "    mean_x = 0.\n",
    "    mean_y = 0.\n",
    "    for ix in range(num):\n",
    "        if i == arr[ix,0]:\n",
    "            x[nd] = arr[ix, 1]\n",
    "            y[nd] = arr[ix, 2]\n",
    "            mean_x += arr[ix, 1]\n",
    "            mean_y += arr[ix, 2]\n",
    "            nd = nd + 1\n",
    "\n",
    "    mean_x = mean_x / (nd - 1)\n",
    "    mean_y = mean_y / (nd - 1)  \n",
    "    plt.scatter(x[:nd], y[:nd])\n",
    "    ax.text(mean_x, mean_y, str(i), fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.grid(visible=True)\n",
    "plt.legend([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], loc =\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Högre siffror skymmer lägre - här en och en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#encoder = load_model(\"mnist_encoder_90ep\")\n",
    "num = 10000\n",
    "arr = np.zeros((num, 3))\n",
    "for ix in range(num):\n",
    "    enc = encoder(mnist_digits[ix][np.newaxis])\n",
    "    arr[ix, 0] = mnist_labels[ix]\n",
    "    arr[ix, 1] = (enc[0].numpy())[0][0]\n",
    "    arr[ix, 2] = (enc[0].numpy())[0][1]\n",
    "\n",
    "#_, ax = plt.subplots(figsize=(10, 7))\n",
    "for i in range(10):\n",
    "    _, ax = plt.subplots(figsize=(10, 7))\n",
    "    x = np.zeros((num, 3)) \n",
    "    y = np.zeros((num, 3))\n",
    "    nd = 0\n",
    "    mean_x = 0.\n",
    "    mean_y = 0.\n",
    "    for ix in range(num):\n",
    "        if i == arr[ix,0]:\n",
    "            x[nd] = arr[ix, 1]\n",
    "            y[nd] = arr[ix, 2]\n",
    "            mean_x += arr[ix, 1]\n",
    "            mean_y += arr[ix, 2]\n",
    "            nd = nd + 1\n",
    "\n",
    "    mean_x = mean_x / (nd - 1)\n",
    "    mean_y = mean_y / (nd - 1)  \n",
    "    plt.scatter(x[:nd], y[:nd], alpha=0.5)\n",
    "    ax.text(mean_x, mean_y, str(i), fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Sampling a grid of images from the 2D latent space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x, y):\n",
    "    res = decoder(np.array([[x, y]]))\n",
    "    plt.imshow(res[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decode(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def image_grid(x_min, x_max, y_min, y_max):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    grid_x = np.linspace(x_min, x_max, n)\n",
    "    grid_y = np.linspace(y_min, y_max, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.axis(\"on\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(-1, 1, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### digit_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_grid(x_min, x_max, y_min, y_max):\n",
    "    import numpy as np\n",
    "\n",
    "    n = 30\n",
    "    row = np.zeros(n, dtype=np.int8)\n",
    "\n",
    "    grid_x = np.linspace(x_min, x_max, n)\n",
    "    grid_y = np.linspace(y_min, y_max, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(28, 28)\n",
    "            digit = (clmodel.predict(digit[np.newaxis]).argmax())\n",
    "            row[j] = digit\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_grid(-1, 1, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# backend för att visa animering\n",
    "matplotlib.use( 'tkagg' )\n",
    "\n",
    "x_min = -1.\n",
    "x_max = 1.\n",
    "x_step = 0.07\n",
    "y_min = -1.\n",
    "y_max = 1.\n",
    "y_step = 0.07\n",
    "\n",
    "# börja i punketn (x_min, y_max)\n",
    "y = y_max\n",
    "fig, ax = plt.subplots()\n",
    "i = 0\n",
    "while y > y_min:\n",
    "    x = x_min\n",
    "    while x < x_max:\n",
    "        ax.cla()\n",
    "        res = decoder(np.array([[x, y]]))\n",
    "        ax.imshow(res[0], cmap='gray')\n",
    "        ax.set_title(\"({:.2f}, {:.2f})\".format(x,y))\n",
    "        plt.pause(0.1)\n",
    "        # gå framåt i raden\n",
    "        x = x + x_step\n",
    "        i = i + 1\n",
    "    # gå ner en rad\n",
    "    y = y - y_step\n",
    "    x = x_max\n",
    "    while x > x_min:\n",
    "        ax.cla()\n",
    "        res = decoder(np.array([[x, y]]))\n",
    "        ax.imshow(res[0], cmap='gray')\n",
    "        ax.set_title(\"({:.2f}, {:.2f})\".format(x,y))\n",
    "        plt.pause(0.1)\n",
    "        # gå bakåt i raden\n",
    "        x = x - x_step\n",
    "        i = i + 1\n",
    "    y = y - y_step\n",
    "plt.close()\n",
    "# återställ till vanlig backend för matplotlib\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter12_part04_variational-autoencoders.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
