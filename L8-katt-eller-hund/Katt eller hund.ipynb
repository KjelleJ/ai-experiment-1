{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "patient-gross",
   "metadata": {},
   "source": [
    "# Katt eller hund?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotta de tre första hundarna och katterna\n",
    "### Finns i samma folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-yugoslavia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(3):\n",
    "    image = Image.open(Path(\"dogs_vs_cats_train\") / (\"dog.\" + str(i) + \".jpg\"))\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "for i in range(0, 3):\n",
    "    image = Image.open(Path(\"dogs_vs_cats_train\") / (\"cat.\" + str(i) + \".jpg\"))\n",
    "    plt.subplot(2, 3, i + 4)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-bedroom",
   "metadata": {},
   "source": [
    "## Skapa två foldrar \"dogs_vs_cats_1000\" och \"dogs_vs_cats_500\" med bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Du behöver bara köra denna cell en gång\n",
    "import os, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "original_dir = Path(\"dogs_vs_cats_train\")\n",
    "new_base_dir = Path(\"dogs_vs_cats_1000\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "# folder med 1000 filer för träning\n",
    "shutil.rmtree(new_base_dir, ignore_errors=True)\n",
    "make_subset(\"train\", start_index=0, end_index=500)\n",
    "make_subset(\"validation\", start_index=500, end_index=750)\n",
    "make_subset(\"test\", start_index=750, end_index=1250)\n",
    "\n",
    "# folder med 500 filer för träning \n",
    "new_base_dir = Path(\"dogs_vs_cats_500\")\n",
    "shutil.rmtree(new_base_dir, ignore_errors=True)\n",
    "make_subset(\"train\", start_index=0, end_index=250)\n",
    "make_subset(\"validation\", start_index=500, end_index=625)\n",
    "make_subset(\"test\", start_index=750, end_index=1250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-check",
   "metadata": {},
   "source": [
    "## Funktion för att skapa datset för träning, validering och test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(new_base_dir, size):\n",
    "    from tensorflow.keras.utils import image_dataset_from_directory\n",
    "    from pathlib import Path\n",
    "\n",
    "    print('Training')\n",
    "    train = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=size,\n",
    "        batch_size=32)\n",
    "    print('Validation')\n",
    "    validation = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=size,\n",
    "        batch_size=32)\n",
    "    print('Test')\n",
    "    test = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(size),\n",
    "        batch_size=32)\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-thanks",
   "metadata": {},
   "source": [
    "# dogs_vs_cats_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skapa dataset från \"dogs_vs_cats_1000\"\n",
    "train_dataset, validation_dataset , test_dataset = create_datasets(Path(\"dogs_vs_cats_1000\"), (160,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-immunology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-destruction",
   "metadata": {},
   "source": [
    "## Definiera en enkel modell som använder \"data augmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    " # definiera en enkel modell med 3 conv-lager\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# sigmoid eftersom modellen har två klasser\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model3 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# binary_crossentropy eftersom modellen har 2 klasser\n",
    "model3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-arbitration",
   "metadata": {},
   "source": [
    "## Träna vår enkla modell från scratch (1000 filer)\n",
    "### Ungefär 30 sekunder per epok => 50 minuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-footage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model3_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model3.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ladda och utvärdera bästa modellen (0.8250 med 2000 filer)\n",
    "test_model = keras.models.load_model(\"model3_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funktion som plottar tränings-historiken\n",
    "def plot_acc_loss():\n",
    "    import matplotlib.pyplot as plt\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-reproduction",
   "metadata": {},
   "source": [
    "## Mobilenet som 'convolutional base' (1000 filer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "conv_base = keras.applications.MobileNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(160, 160, 3))\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-inventory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "print(\"This is the number of trainable weights \"\n",
    "      \"before freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False\n",
    "print(\"This is the number of trainable weights \"\n",
    "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-biotechnology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction1.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# som jämförelse: 0.9730 med 2000 filer\n",
    "test_model = keras.models.load_model(\n",
    "    \"feature_extraction1.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-government",
   "metadata": {},
   "source": [
    "# Hälften så mycket träningsdata (500 filer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skapa dataset från \"dogs_vs_cats_500\"\n",
    "train_dataset, validation_dataset , test_dataset = create_datasets(Path(\"dogs_vs_cats_500\"), (160,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-dairy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction2.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-necessity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\n",
    "    \"feature_extraction2.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-casting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_acc_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-jonathan",
   "metadata": {},
   "source": [
    "## 500 filer + 224x224 bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "conv_base = keras.applications.MobileNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3))\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skapa dataset med bildstorlek 224x2224\n",
    "train_dataset, validation_dataset , test_dataset = create_datasets(Path(\"dogs_vs_cats_500\"), (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-county",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction3.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\n",
    "    \"feature_extraction3.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-caution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_acc_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-literature",
   "metadata": {},
   "source": [
    "# Imagenet utan träning med cats_vs_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-rwanda",
   "metadata": {},
   "source": [
    "### Imagenet klasser: https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b\n",
    "### Katter 281-285, tamhundar 151-268, totalt 1000 klasser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELA MobileNetV2\n",
    "mobile_net = keras.applications.MobileNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=True,\n",
    "    input_shape=(160, 160, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-herald",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mobile_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "hund = 0\n",
    "for i in range(1500, 2500):\n",
    "    pimage = plt.imread(\"cats_vs_dogs_minimal\\\\test\\\\dog\\\\dog.\" + str(i) + \".jpg\")\n",
    "    # lägg till batch- dimension, normalisera till (0.0, 1.0)\n",
    "    pimage = pimage.astype(np.float32)[np.newaxis, ...] / 255.\n",
    "    # ändra storlek till 160x160\n",
    "    pimage = tf.image.resize(pimage, (160, 160))\n",
    "    # bestäm klass\n",
    "    pred = (mobile_net.predict(pimage)).argmax()\n",
    "    if pred >= 151 and pred <= 268: hund = hund + 1\n",
    "print(str(hund) + \" hundar av 1000 korrekt klassificerade. Noggrannhet=\" + str(hund/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-acting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "katt = 0\n",
    "for i in range(1500, 2500):\n",
    "    pimage = plt.imread(\"cats_vs_dogs_minimal\\\\test\\\\cat\\\\cat.\" + str(i) + \".jpg\")\n",
    "    pimage = pimage.astype(np.float32)[np.newaxis, ...] / 255.\n",
    "    pimage = tf.image.resize(pimage, (160, 160))\n",
    "    pred = (mobile_net.predict(pimage)).argmax()\n",
    "    if pred >= 281 and pred <= 285: katt = katt + 1\n",
    "print(str(katt) + \" katter av 1000 korrekt klassificerade. Noggrannhet=\" + str(katt/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noggrannhet totalt=\" + str((hund + katt)/2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-green",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
